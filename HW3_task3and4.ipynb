{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Define useful functions\n",
    "#transform xlsx to dataframe\n",
    "def xlsx_to_csv_pd(path):\n",
    "    data_train = pd.read_excel(path + '15.xlsx')\n",
    "    xls_16 = pd.read_excel(path + '16.xlsx')\n",
    "    xls_17 = pd.read_excel(path + '17.xlsx')\n",
    "    data_train = pd.concat([data_train,xls_16,xls_17])\n",
    "    data_test = pd.read_excel(path + '18.xlsx')\n",
    "    return data_train, data_test\n",
    "\n",
    "def x_y_split(df):\n",
    "    y = df.pop('Comb Unrd Adj FE - Conventional Fuel')\n",
    "    return df,y\n",
    "\n",
    "def choose_column(df):\n",
    "    count = df.shape[0] - df.count()\n",
    "    filtered =  count[count < len(df)*0.2]\n",
    "    index = list(filtered.index)\n",
    "    index = [col for col in index if col.find('EPA') == -1 and col.find('FE') == -1 and col.find('MPG') == -1 and col.find('CO2') == -1 and col.find('Smog') == -1 and col.find('Guzzler') == -1 and col.find('Release Date') == -1 and col.find('Mfr Name') == -1 and col.find('Verify Mfr Cd') == -1]\n",
    "    index = [col for col in index if col.find('Desc') == -1 or col.find('Calc Approach Desc') > -1 or col.find('Var Valve Timing Desc') > -1]    \n",
    "    return df[index], index\n",
    "\n",
    "#def choose_column_noDesc(df):\n",
    "#    count = df.shape[0] - df.count()\n",
    "#    filtered =  count[count < len(df)*0.2]\n",
    "#    index = list(filtered.index)\n",
    "#    index = [col for col in index if col.find('EPA') == -1 and col.find('FE') == -1 and col.find('MPG') == -1 and col.find('CO2') == -1 and col.find('Smog') == -1 and col.find('Guzzler') == -1 and col.find('Release Date') == -1 and col.find('Mfr Name') == -1 and col.find('Verify Mfr Cd') == -1]\n",
    "#    index = [col for col in index if col.find('Desc') == -1 or col.find('Calc Approach Desc') > -1 or col.find('Var Valve Timing Desc') > -1]\n",
    "#    return df[index], index\n",
    "\n",
    "#def fillna_mean(dfo,index,dfto):\n",
    "#    df = dfo.copy()\n",
    "#    dft = dfto.copy()\n",
    "#    for col in index:\n",
    "#        if isinstance(df[col][0],(int,float)):\n",
    "#            df.loc[:,col] = df[col].fillna(df.mean()[col].tolist()[0]).tolist()\n",
    "#            dft.loc[:,col] = dft[col].fillna(df.mean()[col].tolist()[0]).tolist()\n",
    "#        else:\n",
    "#            df.loc[:,col] = df[col].fillna(df.mode()[col].tolist()[0]).tolist()\n",
    "#            dft.loc[:,col] = dft[col].fillna(df.mode()[col].tolist()[0]).tolist()\n",
    "#    return df,dft\n",
    "\n",
    "def fillna_mean(dfo,index,dfto):\n",
    "    df = pd.DataFrame()\n",
    "    dft = pd.DataFrame()\n",
    "    cate = []\n",
    "    num = []\n",
    "    for col in index:\n",
    "        if dfo[col][0].dtype == 'int64' or dfo[col][0].dtype == 'float64':\n",
    "            df[col] = dfo[col].fillna(dfo.mean()[col])\n",
    "            dft[col] = dfto[col].fillna(dfo.mean()[col])\n",
    "            num.append(col)\n",
    "        else:\n",
    "            df[col] = dfo[col].fillna(dfo.mode()[col])\n",
    "            dft[col] = dfto[col].fillna(dfo.mode()[col])\n",
    "            cate.append(col)\n",
    "    return df,dft,cate,num\n",
    "\n",
    "\n",
    "def one_hot_encoding(train,test):\n",
    "    full = pd.concat([train, test]) \n",
    "    extended = pd.get_dummies(full)\n",
    "    boundry = len(train)\n",
    "    train = extended[:boundry]\n",
    "    test = extended[boundry:]\n",
    "    return train, test\n",
    "\n",
    "def rfimpute(df, full_df):\n",
    "    \"\"\"\n",
    "    rfimpute imputes missing values in df using random forest regression.\n",
    "    \n",
    "    Input:\n",
    "        df: a pandas data frame df with missing value, note that choosing\n",
    "            columns must happen before imputing. \n",
    "        full_df: a pandas data frame with missing values filled using mean, \n",
    "                median or mode.\n",
    "    Output: \n",
    "        a pandas data frame having the same dimension as df\n",
    "    \"\"\"\n",
    "    rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "    rf_cla = RandomForestClassifier(n_estimators=100)\n",
    "    X_imputed = full_df.copy()\n",
    "    filtered_train = df.copy()\n",
    "    \n",
    "    for i in range(10):\n",
    "        #print(\"Now loop \"+str(i))\n",
    "        X_imputed_dummies = pd.get_dummies(X_imputed)\n",
    "        last = X_imputed_dummies.copy().as_matrix()\n",
    "        for feature in range(filtered_train.shape[1]):\n",
    "            feature_name = filtered_train.columns.values[feature]\n",
    "            #print(\"Performing on feature \"+feature_name)\n",
    "            \n",
    "            #inds_not_f are column numbers that do not belong to feature column in dummies df\n",
    "            inds_not_f = np.array([col for col in range(X_imputed_dummies.shape[1])\\\n",
    "              if (feature_name + \"_\") not in X_imputed_dummies.columns.values[col]])\n",
    "            if len(inds_not_f) == X_imputed_dummies.shape[1]: #means feature is numerical\n",
    "                  inds_not_f = np.array([col for col in range(X_imputed_dummies.shape[1])\\\n",
    "              if (feature_name) not in X_imputed_dummies.columns.values[col]])\n",
    "        \n",
    "            f_missing = filtered_train.isnull()[feature_name].values\n",
    "            if any(f_missing): \n",
    "            \n",
    "                #Convert df's to numpy matrix\n",
    "                filtered_train_colnames = filtered_train.columns.values\n",
    "                filtered_train_dtypes_dict = filtered_train.dtypes.to_dict()\n",
    "                filtered_train = filtered_train.as_matrix()\n",
    "                X_imputed_colnames = X_imputed.columns.values\n",
    "                X_imputed_dtypes_dict = X_imputed.dtypes.to_dict()\n",
    "                X_imputed = X_imputed.as_matrix()\n",
    "                X_imputed_dummies_colnames = X_imputed_dummies.columns.values\n",
    "                X_imputed_dummies = X_imputed_dummies.as_matrix()\n",
    "                \n",
    "                if feature_name in X_imputed_dummies_colnames: #numerical columns\n",
    "                    #print(feature_name + \" is numerical\")\n",
    "                    rf_reg.fit(X_imputed_dummies[~f_missing][:, inds_not_f], filtered_train[~f_missing, feature])\n",
    "                    X_imputed[f_missing, feature] = rf_reg.predict(\n",
    "                            X_imputed_dummies[f_missing][:, inds_not_f])\n",
    "                else: #for categorical a feature column\n",
    "                    #print(feature_name + \" is categorical\")\n",
    "                    LabEnc = LabelEncoder()\n",
    "                    y = LabEnc.fit_transform(filtered_train[~f_missing, feature])\n",
    "                    rf_cla.fit(X_imputed_dummies[~f_missing][:, inds_not_f], y)\n",
    "                    rf_cla_predicted_Enc = rf_cla.predict(X_imputed_dummies[f_missing][:, inds_not_f])\n",
    "                    rf_cla_predicted = LabEnc.inverse_transform(rf_cla_predicted_Enc)\n",
    "                    X_imputed[f_missing, feature] = rf_cla_predicted\n",
    "                #Convert numpy matrix back to df's\n",
    "                filtered_train = pd.DataFrame(data = filtered_train, columns = filtered_train_colnames)\n",
    "                filtered_train = filtered_train.astype(filtered_train_dtypes_dict)\n",
    "                X_imputed = pd.DataFrame(data = X_imputed, columns = X_imputed_colnames)\n",
    "                X_imputed = X_imputed.astype(X_imputed_dtypes_dict)\n",
    "                X_imputed_dummies = pd.get_dummies(X_imputed)\n",
    "\n",
    "            \n",
    "        now = pd.get_dummies(X_imputed).as_matrix()\n",
    "        if (np.linalg.norm(last - now)) < .5:\n",
    "            return X_imputed\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = xlsx_to_csv_pd('/Users/duxuewei/Documents/sp2018/AML/My_Car_efficiency/')\n",
    "#/Users/haikundu/Desktop/4995AML/hw3/\n",
    "#/Users/duxuewei/Documents/sp2018/AML/My_Car_efficiency/\n",
    "train_x, train_y = x_y_split(train)\n",
    "test_x, test_y = x_y_split(test)\n",
    "filtered_train, column_name = choose_column(train_x)\n",
    "filtered_test = test[column_name]\n",
    "full_train,full_test, cat_cols, num_cols = fillna_mean(filtered_train,column_name,filtered_test)\n",
    "\n",
    "#fillna with random forest regression\n",
    "full_train = rfimpute(filtered_train, full_train)\n",
    "full_test = rfimpute(filtered_test, full_test)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "ohe_train,ohe_test = one_hot_encoding(full_train, full_test)\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ohe_train)\n",
    "X_train_scaled = scaler.transform(ohe_train)\n",
    "X_test_scaled = scaler.transform(ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random forest regression model are {'n_estimators': 14, 'max_depth': 8}\n",
      "Best random forest training score using gridsearch is 0.967169599952\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression Model\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators': [5, 8, 11, 14],\n",
    "                 'max_depth': [2, 4, 6, 8]\n",
    "             }\n",
    "\n",
    "grid_rf_reg = GridSearchCV(rf_reg, param_grid, cv=10)\n",
    "grid_rf_reg.fit(X_train_scaled, train_y)\n",
    "print(\"Best parameters for random forest regression model are \"+str(grid_rf_reg.best_params_))\n",
    "print(\"Best random forest training score using gridsearch is \"+str(grid_rf_reg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for gradient boosting model are {'n_estimators': 70, 'max_depth': 21, 'min_samples_split': 250, 'max_features': 32}\n",
      "Best gradient boosting training score using gridsearch is 0.959684977164\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "gbm_reg = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators':range(40,71,10), \n",
    "                 'max_depth':range(15,25,3), \n",
    "                 'min_samples_split':range(250,1250,300), \n",
    "                 'max_features':range(20,33,4) \n",
    "             }\n",
    "\n",
    "grid_gbm_reg = GridSearchCV(gbm_reg, param_grid, cv=10)\n",
    "grid_gbm_reg.fit(X_train_scaled, train_y)\n",
    "print(\"Best parameters for gradient boosting model are \"+str(grid_gbm_reg.best_params_))\n",
    "print(\"Best gradient boosting training score using gridsearch is \"+str(grid_gbm_reg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbUyNu3dYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106152ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How does y look like\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "plt.hist(train_y.values, bins=22, color = \"#5cb29a\")\n",
    "scatter,loc,mean = lognorm.fit(train_y.values,\n",
    "                               scale=train_y.mean(),\n",
    "                               loc=0)\n",
    "pdf_fitted = lognorm.pdf(np.arange(0,60,.5),scatter,loc,mean)\n",
    "plt.plot(np.arange(0,60,.5),7500*pdf_fitted,'r', color = \"#161491\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = xlsx_to_csv_pd('/Users/duxuewei/Documents/sp2018/AML/My_Car_efficiency/')\n",
    "#/Users/haikundu/Desktop/4995AML/hw3/\n",
    "#/Users/duxuewei/Documents/sp2018/AML/My_Car_efficiency/\n",
    "train_x, train_y = x_y_split(train)\n",
    "train_y = np.log(train_y)\n",
    "test_x, test_y = x_y_split(test)\n",
    "test_y = np.log(test_y)\n",
    "filtered_train, column_name = choose_column(train_x)\n",
    "filtered_test = test[column_name]\n",
    "full_train,full_test, cat_cols, num_cols = fillna_mean(filtered_train,column_name,filtered_test)\n",
    "\n",
    "#fillna with random forest regression\n",
    "full_train = rfimpute(filtered_train, full_train)\n",
    "full_test = rfimpute(filtered_test, full_test)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "ohe_train,ohe_test = one_hot_encoding(full_train, full_test)\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ohe_train)\n",
    "X_train_scaled = scaler.transform(ohe_train)\n",
    "X_test_scaled = scaler.transform(ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random forest regression model are {'n_estimators': 8, 'max_depth': 8}\n",
      "Best random forest training score using gridsearch is 0.970156555041\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression Model\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators': [5, 8, 11, 14],\n",
    "                 'max_depth': [2, 4, 6, 8]\n",
    "             }\n",
    "\n",
    "grid_rf_reg = GridSearchCV(rf_reg, param_grid, cv=10)\n",
    "grid_rf_reg.fit(X_train_scaled, train_y)\n",
    "print(\"Best parameters for random forest regression model are \"+str(grid_rf_reg.best_params_))\n",
    "print(\"Best random forest training score using gridsearch is \"+str(grid_rf_reg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for gradient boosting model are {'n_estimators': 70, 'max_depth': 21, 'min_samples_split': 250, 'max_features': 32}\n",
      "Best gradient boosting training score using gridsearch is 0.965020113475\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "gbm_reg = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators':range(40,71,10), \n",
    "                 'max_depth':range(15,25,3), \n",
    "                 'min_samples_split':range(250,1250,300), \n",
    "                 'max_features':range(20,33,4) \n",
    "             }\n",
    "\n",
    "grid_gbm_reg = GridSearchCV(gbm_reg, param_grid, cv=10)\n",
    "grid_gbm_reg.fit(X_train_scaled, train_y)\n",
    "print(\"Best parameters for gradient boosting model are \"+str(grid_gbm_reg.best_params_))\n",
    "print(\"Best gradient boosting training score using gridsearch is \"+str(grid_gbm_reg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input Data has 1662 columns\n",
      "Important columns are: ['Eng Displ' 'Annual Fuel1 Cost - Conventional Fuel'\n",
      " 'GHG Rating (1-10 rating on Label)_5'\n",
      " 'GHG Rating (1-10 rating on Label)_4'\n",
      " 'GHG Rating (1-10 rating on Label)_6'\n",
      " 'GHG Rating (1-10 rating on Label)_3'\n",
      " 'GHG Rating (1-10 rating on Label)_1' '# Cyl'\n",
      " 'GHG Rating (1-10 rating on Label)_7'\n",
      " 'GHG Rating (1-10 rating on Label)_2'\n",
      " 'GHG Rating (1-10 rating on Label)_10'\n",
      " 'Stop/Start System (Engine Management System) Code_Y' 'Model Year'\n",
      " 'GHG Rating (1-10 rating on Label)_8'\n",
      " 'GHG Rating (1-10 rating on Label)_9' 'Fuel Usage  - Conventional Fuel_G'\n",
      " 'Fuel Usage  - Conventional Fuel_DU' 'Carline Class'\n",
      " 'Index (Model Type Index)' 'Var Valve Lift?_Y'\n",
      " 'Var Valve Timing Desc_Variable Valve Timing System with inlet'\n",
      " 'Fuel Metering Sys Cd_CRDI' 'Var Valve Timing?_Y' 'Var Valve Lift?_N'\n",
      " 'Unique Label?_N' 'Max Ethanol % - Gasoline'\n",
      " 'Fuel Usage  - Conventional Fuel_GP' '# Gears'\n",
      " 'Fuel Usage  - Conventional Fuel_GPR'\n",
      " 'Var Valve Timing Desc_variable valve timing at inlet and outlet valves']\n"
     ]
    }
   ],
   "source": [
    "##Best model\n",
    "rf_best = grid_rf_reg.best_estimator_\n",
    "rf_feature_importances = rf_best.feature_importances_\n",
    "print(\"Model input Data has \" + str(len(rf_feature_importances)) + \" columns\")\n",
    "#ohe_train, ohe_test\n",
    "rf_feature_importances_index = rf_feature_importances.argsort()[-30:][::-1]\n",
    "print(\"Important columns are: \" + str(ohe_train.columns.values[rf_feature_importances_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best random forest test score is 0.946690694573\n"
     ]
    }
   ],
   "source": [
    "##Test set performance\n",
    "rf_test_score = rf_best.score(X_test_scaled, test_y)\n",
    "print(\"Best random forest test score is \"+ str(rf_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest w/ log-transformed y dropping irrelevant columns has test set score 0.955005971143\n"
     ]
    }
   ],
   "source": [
    "##Dropping irrelevant columns and run random forest w/ transformed y again\n",
    "ohe_train = ohe_train[rf_feature_importances_index]\n",
    "ohe_test = ohe_test[rf_feature_importances_index]\n",
    "#Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ohe_train)\n",
    "X_train_scaled = scaler.transform(ohe_train)\n",
    "X_test_scaled = scaler.transform(ohe_test)\n",
    "\n",
    "rf_reg_best = RandomForestRegressor(n_estimators = 8, max_depth = 8)\n",
    "rf_reg_best.fit(X_train_scaled, train_y)\n",
    "\n",
    "print(\"Random Forest w/ log-transformed y dropping irrelevant columns has test set score \" + str(rf_reg_best.score(X_test_scaled, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
